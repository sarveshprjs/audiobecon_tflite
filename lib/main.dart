import 'dart:async';
import 'dart:io';
import 'dart:typed_data';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:permission_handler/permission_handler.dart';
import 'package:flutter_sound/flutter_sound.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as p;
import 'package:tflite_flutter/tflite_flutter.dart';

void main() {
  runApp(const MyApp());
}

class MyApp extends StatelessWidget {
  const MyApp({super.key});

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Sound Classifier',
      theme: ThemeData(
        primarySwatch: Colors.blue,
        useMaterial3: true,
      ),
      home: const SoundPage(),
    );
  }
}

class SoundPage extends StatefulWidget {
  const SoundPage({super.key});

  @override
  State<SoundPage> createState() => _SoundPageState();
}

class _SoundPageState extends State<SoundPage> with SingleTickerProviderStateMixin {
  final FlutterSoundRecorder _audioRecorder = FlutterSoundRecorder();
  final SoundClassifier _classifier = SoundClassifier();
  bool _isRecording = false;
  bool _hasPermission = false;
  double _dbLevel = 0.0;
  late AnimationController _animationController;
  String _processingTime = "0 ms";
  late List<double> _audioBars;
  Timer? _visualizerTimer;
  Timer? _classificationTimer;
  String _currentSoundLabel = "No sound detected";
  double _currentConfidence = 0.0;

  @override
  void initState() {
    super.initState();
    _animationController = AnimationController(
      vsync: this,
      duration: const Duration(milliseconds: 300),
    );
    _audioBars = List.generate(20, (index) => 0.0);
    _initRecorder();
    _classifier.loadModel();
  }

  Future<void> _initRecorder() async {
    try {
      final status = await Permission.microphone.request();
      setState(() {
        _hasPermission = status.isGranted;
      });

      if (_hasPermission) {
        await _audioRecorder.openRecorder();
        _audioRecorder.setSubscriptionDuration(const Duration(milliseconds: 100));
      } else {
        debugPrint("‚ùå Microphone permission denied!");
      }
    } catch (e) {
      debugPrint("Error initializing recorder: $e");
    }
  }

  void _updateVisualizer() {
    if (_isRecording) {
      setState(() {
        for (int i = 0; i < _audioBars.length - 1; i++) {
          _audioBars[i] = _audioBars[i + 1];
        }
        _audioBars[_audioBars.length - 1] = (_dbLevel / 100).clamp(0.0, 1.0);
      });
    }
  }

  Future<void> _startRecording() async {
    try {
      if (!_hasPermission) {
        await _initRecorder();
        return;
      }

      if (!_audioRecorder.isRecording) {
        final directory = await getApplicationDocumentsDirectory();
        final filePath = p.join(directory.path, 'my_recording.wav');

        await _audioRecorder.startRecorder(
          toFile: filePath,
          codec: Codec.pcm16WAV,
          sampleRate: 16000,
        );

        setState(() {
          _isRecording = true;
        });

        _animationController.repeat(reverse: true);

        _visualizerTimer = Timer.periodic(const Duration(milliseconds: 50), (timer) {
          _updateVisualizer();
        });

        // Start classification
        _startClassification();

        _audioRecorder.onProgress!.listen((recording) {
          setState(() {
            _dbLevel = recording.decibels ?? 0.0;
          });
        });
      }
    } catch (e) {
      debugPrint("Error starting recording: $e");
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(content: Text("Failed to start recording")),
      );
    }
  }

  void _startClassification() {
    Timer.periodic(const Duration(seconds: 2), (timer) async {
      if (!_isRecording) {
        timer.cancel();
        return;
      }

      try {
        final classification = await _classifier.classifySound(_dbLevel);
        if (classification != null) {
          setState(() {
            _currentSoundLabel = classification['label'] ?? "Unknown";
            _currentConfidence = classification['confidence'] ?? 0.0;
          });
        }
      } catch (e) {
        debugPrint("Classification error: $e");
      }
    });
  }

  Future<void> _stopRecording() async {
    try {
      if (_audioRecorder.isRecording) {
        final path = await _audioRecorder.stopRecorder();
        setState(() {
          _isRecording = false;
          _dbLevel = 0.0;
          _currentSoundLabel = "No sound detected";
          _currentConfidence = 0.0;
        });

        _animationController.stop();
        _visualizerTimer?.cancel();
        _audioBars = List.generate(20, (index) => 0.0);

        debugPrint("Recording saved at: $path");
        ScaffoldMessenger.of(context).showSnackBar(
          const SnackBar(content: Text("Recording saved!")),
        );
      }
    } catch (e) {
      debugPrint("Error stopping recording: $e");
    }
  }

  Color _getSoundColor(double dbLevel) {
    if (dbLevel < 30) return Colors.green;
    if (dbLevel < 50) return Colors.lightGreen;
    if (dbLevel < 70) return Colors.yellow;
    if (dbLevel < 85) return Colors.orange;
    if (dbLevel < 100) return Colors.deepOrange;
    return Colors.red;
  }

  @override
  void dispose() {
    _animationController.dispose();
    _visualizerTimer?.cancel();
    _audioRecorder.closeRecorder();
    _classifier.dispose();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    final soundColor = _getSoundColor(_dbLevel);

    return Scaffold(
      backgroundColor: Colors.grey[50],
      appBar: AppBar(
        title: const Text("üéµ Sound Classifier"),
        backgroundColor: Colors.blue,
        foregroundColor: Colors.white,
        elevation: 4,
      ),
      body: Center(
        child: Padding(
          padding: const EdgeInsets.all(20.0),
          child: Column(
            mainAxisAlignment: MainAxisAlignment.center,
            children: [
              // Visualizer
              Container(
                height: 150,
                width: double.infinity,
                decoration: BoxDecoration(
                  color: Colors.black.withOpacity(0.8),
                  borderRadius: BorderRadius.circular(16),
                  boxShadow: [
                    BoxShadow(
                      color: Colors.black.withOpacity(0.2),
                      blurRadius: 10,
                      offset: const Offset(0, 4),
                    ),
                  ],
                ),
                child: Row(
                  mainAxisAlignment: MainAxisAlignment.spaceEvenly,
                  crossAxisAlignment: CrossAxisAlignment.end,
                  children: _audioBars.map((height) {
                    return AnimatedContainer(
                      duration: const Duration(milliseconds: 100),
                      width: 8,
                      height: height * 120 + 10,
                      decoration: BoxDecoration(
                        color: soundColor.withOpacity(0.8),
                        borderRadius: BorderRadius.circular(4),
                        gradient: LinearGradient(
                          colors: [
                            soundColor.withOpacity(0.9),
                            soundColor.withOpacity(0.6),
                          ],
                          begin: Alignment.topCenter,
                          end: Alignment.bottomCenter,
                        ),
                      ),
                    );
                  }).toList(),
                ),
              ),

              const SizedBox(height: 30),

              // Sound Level Card
              Card(
                elevation: 6,
                shape: RoundedRectangleBorder(
                  borderRadius: BorderRadius.circular(16),
                ),
                child: Padding(
                  padding: const EdgeInsets.all(20.0),
                  child: Column(
                    children: [
                      Text(
                        "${_dbLevel.toStringAsFixed(1)} dB",
                        style: TextStyle(
                          fontSize: 32,
                          fontWeight: FontWeight.bold,
                          color: soundColor,
                        ),
                      ),
                      const SizedBox(height: 8),
                      Text(
                        _currentSoundLabel,
                        style: TextStyle(
                          fontSize: 18,
                          color: soundColor.withOpacity(0.8),
                          fontWeight: FontWeight.w500,
                        ),
                        textAlign: TextAlign.center,
                      ),
                      const SizedBox(height: 8),
                      Text(
                        "Confidence: ${(_currentConfidence * 100).toStringAsFixed(1)}%",
                        style: const TextStyle(
                          fontSize: 14,
                          color: Colors.grey,
                        ),
                      ),
                    ],
                  ),
                ),
              ),

              const SizedBox(height: 30),

              // Status Indicator
              Row(
                mainAxisAlignment: MainAxisAlignment.center,
                children: [
                  Icon(
                    _isRecording ? Icons.circle : Icons.circle_outlined,
                    color: _isRecording ? Colors.red : Colors.grey,
                    size: 16,
                  ),
                  const SizedBox(width: 8),
                  Text(
                    _isRecording ? "Recording..." : "Ready to record",
                    style: TextStyle(
                      fontSize: 16,
                      color: _isRecording ? Colors.red : Colors.grey,
                    ),
                  ),
                ],
              ),

              const SizedBox(height: 30),

              // Buttons
              Row(
                mainAxisAlignment: MainAxisAlignment.center,
                children: [
                  ElevatedButton.icon(
                    onPressed: _isRecording ? null : _startRecording,
                    icon: const Icon(Icons.mic, size: 20),
                    label: const Text("Start Recording"),
                    style: ElevatedButton.styleFrom(
                      backgroundColor: Colors.green,
                      foregroundColor: Colors.white,
                      padding: const EdgeInsets.symmetric(horizontal: 24, vertical: 16),
                      shape: RoundedRectangleBorder(
                        borderRadius: BorderRadius.circular(12),
                      ),
                    ),
                  ),
                  const SizedBox(width: 16),
                  ElevatedButton.icon(
                    onPressed: _isRecording ? _stopRecording : null,
                    icon: const Icon(Icons.stop, size: 20),
                    label: const Text("Stop"),
                    style: ElevatedButton.styleFrom(
                      backgroundColor: Colors.red,
                      foregroundColor: Colors.white,
                      padding: const EdgeInsets.symmetric(horizontal: 24, vertical: 16),
                      shape: RoundedRectangleBorder(
                        borderRadius: BorderRadius.circular(12),
                      ),
                    ),
                  ),
                ],
              ),

              if (!_hasPermission) ...[
                const SizedBox(height: 20),
                Text(
                  "Microphone permission required!",
                  style: TextStyle(
                    color: Colors.red[700],
                    fontWeight: FontWeight.w500,
                  ),
                ),
              ],
            ],
          ),
        ),
      ),
    );
  }
}

class SoundClassifier {
  Interpreter? _interpreter;
  final List<String> _labels = [
    "Speech", "Music", "Noise", "Silence", "Animal", "Vehicle", "Nature",
    "Alarm", "Siren", "Applause", "Laughter", "Crying", "Footsteps",
    "Knocking", "Doorbell", "Water", "Wind", "Thunder", "Fire", "Explosion"
  ];

  Future<void> loadModel() async {
    try {
      // Placeholder for model loading
      debugPrint("Sound classifier initialized");
    } catch (e) {
      debugPrint("Error initializing classifier: $e");
    }
  }

  Future<Map<String, dynamic>?> classifySound(double dbLevel) async {
    try {
      // Simulate classification based on dB level
      await Future.delayed(const Duration(milliseconds: 300));

      // More realistic simulation based on dB level
      String label;
      double confidence;

      if (dbLevel < 30) {
        label = "Silence";
        confidence = 0.8 + (DateTime.now().millisecond % 200) / 1000;
      } else if (dbLevel < 50) {
        label = "Background Noise";
        confidence = 0.7 + (DateTime.now().millisecond % 300) / 1000;
      } else if (dbLevel < 70) {
        label = _labels[DateTime.now().millisecond % 3]; // Speech/Music/Noise
        confidence = 0.6 + (DateTime.now().millisecond % 400) / 1000;
      } else {
        label = _labels[3 + (DateTime.now().millisecond % (_labels.length - 3))];
        confidence = 0.5 + (DateTime.now().millisecond % 500) / 1000;
      }

      return {
        'label': label,
        'confidence': confidence.clamp(0.0, 1.0),
      };
    } catch (e) {
      debugPrint("Classification error: $e");
      return null;
    }
  }

  void dispose() {
    _interpreter?.close();
  }
}
